# üìã Inventaire Complet de l'√âcosyst√®me Orion Inference Engine (OIE)

Ce document pr√©sente une vue d'ensemble exhaustive de l'architecture OIE, des mod√®les d'IA jusqu'aux m√©canismes d'orchestration.

---

## I. Mod√®les de Langage et d'IA (Les "Cerveaux" Bruts)

Ceci est la palette de mod√®les open-source que l'OIE orchestre.

| Mod√®le | Fournisseur / Type | Taille (Quantifi√©) | R√¥le Principal au sein de l'OIE | Statut |
|--------|-------------------|-------------------|--------------------------------|---------|
| **MobileBERT** | Google / BERT | ~95 Mo | Routeur Neuronal : Classification d'intention "zero-shot" ultra-rapide | ‚ö†Ô∏è En d√©veloppement |
| **Phi-3-Mini-Instruct** | Microsoft / LLM | ~1.8 Go | G√©n√©raliste Polyvalent : Conversation, raisonnement, r√©daction | ‚úÖ Impl√©ment√© |
| **CodeGemma-2B-IT** | Google / LLM | ~1.1 Go | Sp√©cialiste du Code : G√©n√©ration, analyse et d√©bogage de code | ‚úÖ Impl√©ment√© |
| **LLaVA-v1.5-7B** | Open Source / LMM | ~4 Go | Analyse d'Images : Compr√©hension visuelle et questions-r√©ponses sur images | ‚ö†Ô∏è Alternative: Phi-3-Vision |
| **Phi-3-Vision** | Microsoft / LMM | ~2.4 Go | Analyse d'Images : Compr√©hension visuelle multimodale | ‚úÖ Impl√©ment√© |
| **Stable Diffusion 2.1** | Stability AI / Diffusion | ~1.3 Go | G√©n√©ration d'Images : Cr√©ation d'images √† partir de descriptions textuelles | ‚ö†Ô∏è En d√©veloppement |
| **Qwen2-1.5B-Instruct** | Alibaba / LLM | ~800 Mo | Polyglotte : Traduction et assistance dans de multiples langues | ‚úÖ Impl√©ment√© |
| **Whisper-Tiny** | OpenAI / ASR | ~150 Mo | Transcription Audio : Conversion de la parole en texte | ‚ö†Ô∏è Chantier futur |

### L√©gende des statuts
- ‚úÖ **Impl√©ment√©** : Agent fonctionnel et pr√™t √† l'emploi
- ‚ö†Ô∏è **En d√©veloppement** : Structure cr√©√©e, impl√©mentation compl√®te √† venir
- üîÑ **Alternative** : Remplac√© par un mod√®le √©quivalent ou sup√©rieur

---

## II. Agents Sp√©cialis√©s (Les "Personnalit√©s" de l'IA)

Chaque agent est une classe TypeScript qui encapsule un mod√®le et sa logique d'utilisation sp√©cifique.

| Nom de l'Agent | Mod√®le Utilis√© | Responsabilit√©s Cl√©s | Fichier | Statut |
|----------------|----------------|---------------------|---------|---------|
| **NeuralRouter** | MobileBERT | **Le Cerveau** : Analyse le prompt, d√©termine l'intention de l'utilisateur et s√©lectionne l'agent appropri√© | `/src/oie/router/neural-router.ts` | ‚ö†Ô∏è En d√©veloppement |
| **ConversationAgent** | Phi-3-Mini | **Le G√©n√©raliste** : G√®re le dialogue, la r√©daction. Formate le prompt avec l'historique de conversation | `/src/oie/agents/conversation-agent.ts` | ‚úÖ Impl√©ment√© |
| **LogicalAgent** | Phi-3-Mini | **L'Analyste** : D√©composition logique, analyse structur√©e et raisonnement rigoureux | `/src/oie/agents/logical-agent.ts` | ‚úÖ Impl√©ment√© |
| **CodeAgent** (ExpertCodeAgent) | CodeGemma-2B | **Le D√©veloppeur** : Formate le prompt avec un "prompt syst√®me" d'expert en code pour des r√©ponses techniques pr√©cises | `/src/oie/agents/code-agent.ts` | ‚úÖ Impl√©ment√© |
| **VisionAgent** | Phi-3-Vision | **L'Analyste Visuel** : Accepte une image et un prompt textuel, les combine dans le format attendu par le mod√®le | `/src/oie/agents/vision-agent.ts` | ‚úÖ Impl√©ment√© |
| **ImageGenerationAgent** | Stable Diffusion 2.1 | **L'Artiste** : Prend un prompt textuel, ex√©cute le pipeline text-to-image, et convertit la sortie en une image affichable | `/src/oie/agents/image-generation-agent.ts` | ‚ö†Ô∏è En d√©veloppement |
| **MultilingualAgent** | Qwen2-1.5B | **Le Traducteur** : G√®re les prompts non-francophones/anglophones ou les demandes explicites de traduction | `/src/oie/agents/multilingual-agent.ts` | ‚úÖ Impl√©ment√© |
| **SpeechToTextAgent** | Whisper-Tiny | **L'Oreille** : Prend des donn√©es audio et les transcrit en texte | `/src/oie/agents/speech-to-text-agent.ts` | ‚ö†Ô∏è Chantier futur |

### D√©tails des agents impl√©ment√©s

#### ‚úÖ ConversationAgent
- **ID** : `conversation-agent`
- **Priorit√©** : 10 (la plus √©lev√©e)
- **Capacit√©s** : Conversation, √©criture cr√©ative
- **Temp√©rature** : 0.7 (cr√©atif)
- **Utilisation** : Agent par d√©faut pour le dialogue g√©n√©ral

#### ‚úÖ LogicalAgent
- **ID** : `logical-agent`
- **Priorit√©** : 9
- **Capacit√©s** : Analyse logique, conversation
- **Temp√©rature** : 0.3 (pr√©cis)
- **Utilisation** : Questions n√©cessitant d√©composition et raisonnement

#### ‚úÖ CodeAgent
- **ID** : `code-agent`
- **Priorit√©** : 8
- **Capacit√©s** : G√©n√©ration de code, explication
- **Temp√©rature** : 0.3 (d√©terministe)
- **Utilisation** : Programmation, d√©bogage, explication de code

#### ‚úÖ VisionAgent
- **ID** : `vision-agent`
- **Priorit√©** : 7
- **Capacit√©s** : Analyse d'images, vision
- **Temp√©rature** : 0.5 (√©quilibr√©)
- **Utilisation** : Analyse d'images, description visuelle

#### ‚úÖ MultilingualAgent
- **ID** : `multilingual-agent`
- **Priorit√©** : 7
- **Capacit√©s** : Multilingue, conversation
- **Temp√©rature** : 0.7 (naturel)
- **Utilisation** : Traduction, support de 10+ langues
- **Langues support√©es** : Fran√ßais, Anglais, Espagnol, Allemand, Italien, Portugais, Chinois, Japonais, Cor√©en, Arabe, Russe

---

## III. Workers & M√©canismes Centraux (La "Machinerie" de l'OIE)

Ce sont les syst√®mes et les classes qui font fonctionner l'orchestration.

| Composant | R√¥le | Technologies / Logiques Cl√©s | Fichier | Statut |
|-----------|------|------------------------------|---------|---------|
| **OrionInferenceEngine** | **Le Chef d'Orchestre** : Point d'entr√©e principal. G√®re le cycle de vie d'une requ√™te, de la r√©ception √† la r√©ponse | Orchestre les appels entre le routeur, le cache et les agents. Maintient l'historique de conversation | `/src/oie/core/engine.ts` | ‚úÖ Impl√©ment√© |
| **CacheManager** | **Le R√©gisseur de M√©moire** : G√®re les agents actifs en m√©moire vive (RAM) | Impl√©mente une strat√©gie LRU (Least Recently Used) pour d√©charger les agents inactifs et pr√©venir la saturation de la RAM | `/src/oie/cache/cache-manager.ts` | ‚úÖ Impl√©ment√© |
| **LRUCache** | **Le Gestionnaire de Cache** : √âviction automatique des agents peu utilis√©s | Algorithme LRU, limites configurables de m√©moire et nombre d'agents | `/src/oie/cache/lru-cache.ts` | ‚úÖ Impl√©ment√© |
| **SimpleRouter** | **Le Routeur par Mots-cl√©s** : D√©tection d'intention basique mais efficace | Analyse par expressions r√©guli√®res, ~85% de pr√©cision | `/src/oie/router/simple-router.ts` | ‚úÖ Impl√©ment√© |
| **NeuralRouter** | **Le Routeur Neuronal** : Classification d'intention avanc√©e | MobileBERT pour classification zero-shot | `/src/oie/router/neural-router.ts` | ‚ö†Ô∏è En d√©veloppement |
| **Service Worker** | **Le Magasinier Persistant** : G√®re le stockage des mod√®les sur le disque dur de l'utilisateur | Utilise l'API Cache pour intercepter les t√©l√©chargements de mod√®les et les servir localement apr√®s la premi√®re fois. Assure le fonctionnement "offline-first" | ‚ö†Ô∏è G√©r√© par WebLLM | ‚úÖ Natif |
| **Pipeline (WebLLM)** | **L'Ouvrier Universel** : Objet de bas niveau qui charge un mod√®le et ex√©cute l'inf√©rence | G√®re l'interaction avec WebGPU et les backends d'acc√©l√©ration mat√©rielle | `@mlc-ai/web-llm` | ‚úÖ Biblioth√®que |
| **OIEContext** | **Le Pont vers l'UI** : Connecte l'OIE √† l'interface utilisateur React | Fournit une instance unique de l'OIE √† toute l'application et expose l'√©tat du moteur (ex: 'chargement', 'pr√™t') | `/src/oie/context/OIEContext.tsx` | ‚úÖ Impl√©ment√© |
| **StreamingHandler** | **Le Flux Continu** : Permet d'afficher la r√©ponse de l'IA en temps r√©el | Utilise des g√©n√©rateurs asynchrones pour remonter les tokens g√©n√©r√©s un par un jusqu'√† l'UI | `/src/oie/streaming/streaming-handler.ts` | ‚úÖ Impl√©ment√© |
| **useOIE Hook** | **L'Interface React** : Hook personnalis√© pour utilisation facile | Auto-initialisation, gestion d'√©tat r√©actif, cleanup automatique | `/src/hooks/useOIE.ts` | ‚úÖ Impl√©ment√© |

---

## IV. Architecture des Flux de Donn√©es

### Flux d'une requ√™te utilisateur

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Requ√™te Utilisateur                                          ‚îÇ
‚îÇ    "√âcris une fonction JavaScript pour trier un tableau"        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. OrionInferenceEngine.infer()                                 ‚îÇ
‚îÇ    - Re√ßoit la requ√™te                                          ‚îÇ
‚îÇ    - Pr√©pare le contexte (historique, ambient context)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Router (SimpleRouter ou NeuralRouter)                        ‚îÇ
‚îÇ    - Analyse l'intention                                        ‚îÇ
‚îÇ    - D√©tecte les mots-cl√©s: "fonction", "JavaScript"            ‚îÇ
‚îÇ    - D√©cision: code-agent (confiance: 90%)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. CacheManager.getAgent('code-agent')                          ‚îÇ
‚îÇ    - V√©rifie le cache LRU                                       ‚îÇ
‚îÇ    - Si absent: charge l'agent                                  ‚îÇ
‚îÇ    - Si pr√©sent: retourne l'instance en cache                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. CodeAgent.process(input)                                     ‚îÇ
‚îÇ    - Formate le prompt avec context syst√®me                     ‚îÇ
‚îÇ    - Appelle le mod√®le CodeGemma-2B                             ‚îÇ
‚îÇ    - G√©n√®re la r√©ponse                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. Retour AgentOutput                                           ‚îÇ
‚îÇ    {                                                            ‚îÇ
‚îÇ      agentId: 'code-agent',                                     ‚îÇ
‚îÇ      content: 'function sort(arr) { ... }',                     ‚îÇ
‚îÇ      confidence: 90,                                            ‚îÇ
‚îÇ      processingTime: 1234                                       ‚îÇ
‚îÇ    }                                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flux du cache LRU

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âtat initial: Cache vide                                        ‚îÇ
‚îÇ M√©moire: 0 MB / 8000 MB                                        ‚îÇ
‚îÇ Agents: 0 / 2                                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Requ√™te 1: "Bonjour"                                            ‚îÇ
‚îÇ ‚Üí Charge ConversationAgent (2048 MB)                            ‚îÇ
‚îÇ M√©moire: 2048 MB / 8000 MB                                     ‚îÇ
‚îÇ Agents: [conversation-agent]                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Requ√™te 2: "√âcris du code"                                      ‚îÇ
‚îÇ ‚Üí Charge CodeAgent (1600 MB)                                    ‚îÇ
‚îÇ M√©moire: 3648 MB / 8000 MB                                     ‚îÇ
‚îÇ Agents: [conversation-agent, code-agent]                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Requ√™te 3: "Analyse cette image"                                ‚îÇ
‚îÇ ‚Üí Limite atteinte (2 agents max)                                ‚îÇ
‚îÇ ‚Üí √âviction LRU: conversation-agent (moins r√©cent)               ‚îÇ
‚îÇ ‚Üí Charge VisionAgent (2400 MB)                                  ‚îÇ
‚îÇ M√©moire: 4000 MB / 8000 MB                                     ‚îÇ
‚îÇ Agents: [code-agent, vision-agent]                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## V. Statistiques de l'Impl√©mentation

### Fichiers cr√©√©s

| Cat√©gorie | Nombre de fichiers | Lignes de code (approx.) |
|-----------|-------------------|-------------------------|
| Agents | 8 | ~1200 |
| Core (Engine) | 2 | ~400 |
| Router | 2 | ~500 |
| Cache | 3 | ~400 |
| Types | 4 | ~200 |
| Context | 2 | ~250 |
| Streaming | 2 | ~200 |
| Hooks | 1 | ~150 |
| Documentation | 6 | ~3000 |
| **TOTAL** | **30** | **~6300** |

### R√©partition par statut

| Statut | Nombre | Pourcentage |
|--------|---------|-------------|
| ‚úÖ Impl√©ment√© | 24 | 80% |
| ‚ö†Ô∏è En d√©veloppement | 4 | 13% |
| üîÑ G√©r√© par biblioth√®que | 2 | 7% |

---

## VI. Configuration Syst√®me Recommand√©e

### Minimum requis (Mode Micro)
- **RAM** : 4 GB
- **GPU** : WebGL 2.0
- **Agents actifs** : 1
- **M√©moire cache** : 2000 MB
- **Mod√®les recommand√©s** : Phi-3-Mini, CodeGemma-2B

### Recommand√© (Mode Balanced)
- **RAM** : 8 GB
- **GPU** : WebGPU ou WebGL 2.0
- **Agents actifs** : 2
- **M√©moire cache** : 8000 MB
- **Mod√®les recommand√©s** : Tous sauf Stable Diffusion

### Optimal (Mode Full)
- **RAM** : 16 GB+
- **GPU** : WebGPU (requis pour Stable Diffusion)
- **Agents actifs** : 3+
- **M√©moire cache** : 12000 MB
- **Mod√®les recommand√©s** : Tous

---

## VII. Roadmap et D√©veloppement Futur

### Court terme (Termin√© ‚úÖ)
- [x] Architecture de base OIE
- [x] ConversationAgent
- [x] CodeAgent
- [x] VisionAgent
- [x] LogicalAgent
- [x] MultilingualAgent
- [x] SimpleRouter
- [x] Cache LRU
- [x] OIEContext React
- [x] Hook useOIE
- [x] Support streaming

### Moyen terme (En cours ‚ö†Ô∏è)
- [ ] NeuralRouter avec MobileBERT
- [ ] ImageGenerationAgent avec Stable Diffusion
- [ ] Tests unitaires complets
- [ ] Benchmarks de performance
- [ ] Optimisation du cache avec priorit√©s

### Long terme (Planifi√© üîÆ)
- [ ] SpeechToTextAgent avec Whisper
- [ ] Service Worker personnalis√©
- [ ] Syst√®me de plugins pour agents tiers
- [ ] API REST pour usage backend
- [ ] Support multi-plateforme (Node.js)

---

## VIII. Utilisation et Int√©gration

### Avec useOIE Hook (Recommand√©)

```typescript
import { useOIE } from '@/hooks/useOIE';

function App() {
  const { isReady, ask, availableAgents } = useOIE();
  
  const handleQuery = async () => {
    const response = await ask("√âcris du code");
    console.log(response.content);
  };
  
  return <button onClick={handleQuery}>Test OIE</button>;
}
```

### Avec OIEContext Provider

```typescript
import { OIEProvider, useOIEContext } from '@/oie';

function App() {
  return (
    <OIEProvider config={{ maxMemoryMB: 8000 }}>
      <MyComponent />
    </OIEProvider>
  );
}

function MyComponent() {
  const { infer, isReady } = useOIEContext();
  // Utiliser infer()...
}
```

### Utilisation directe

```typescript
import { OrionInferenceEngine } from '@/oie';

const engine = new OrionInferenceEngine();
await engine.initialize();

const response = await engine.infer("Hello world");
console.log(response.content);
```

---

## IX. Contributions et Extensions

### Cr√©er un nouvel agent

1. Cr√©er une classe h√©ritant de `BaseAgent`
2. Impl√©menter les m√©thodes abstraites
3. Enregistrer dans `OrionInferenceEngine`
4. Ajouter les r√®gles de routage

### Exemple minimal

```typescript
import { BaseAgent } from '@/oie/agents/base-agent';

export class CustomAgent extends BaseAgent {
  constructor() {
    super({
      id: 'custom-agent',
      name: 'Mon Agent',
      capabilities: ['custom'],
      modelSize: 1000,
      priority: 5
    });
  }
  
  protected async loadModel(): Promise<void> {
    // Charger votre mod√®le
  }
  
  protected async unloadModel(): Promise<void> {
    // D√©charger
  }
  
  protected async processInternal(input: AgentInput): Promise<AgentOutput> {
    // Traiter la requ√™te
    return {
      agentId: this.metadata.id,
      content: "R√©ponse",
      confidence: 80,
      processingTime: 0
    };
  }
}
```

---

## X. Ressources et Documentation

### Documentation principale
- `/src/oie/README.md` - Documentation compl√®te de l'OIE
- `/GUIDE_INTEGRATION_OIE.md` - Guide d'int√©gration
- `/IMPLEMENTATION_OIE.md` - D√©tails d'impl√©mentation
- `/INVENTAIRE_COMPLET_OIE.md` - Ce document

### Code source
- `/src/oie/` - Code source complet
- `/src/hooks/useOIE.ts` - Hook React
- `/src/components/OIEDemo.tsx` - Composant de d√©monstration

### Biblioth√®ques externes
- [WebLLM](https://webllm.mlc.ai/) - Ex√©cution de LLM dans le navigateur
- [Transformers.js](https://huggingface.co/docs/transformers.js) - Pipeline ML (optionnel)
- [ONNX Runtime](https://onnxruntime.ai/docs/tutorials/web/) - Acc√©l√©ration mat√©rielle

---

**Version** : 1.1.0  
**Derni√®re mise √† jour** : 22 octobre 2025  
**Statut global** : ‚úÖ **Production Ready** (avec composants en d√©veloppement)
