# Recette ORION Vision & Logique v1
# Agent hybride pour analyse visuelle avec raisonnement
# 
# NOTE IMPORTANTE:
# Les mod√®les vision (multimodaux) sont complexes √† fusionner car ils ont
# deux composants: un encodeur d'images (CLIP) et un LLM.
# 
# Cette recette fusionne uniquement les LLM des mod√®les vision.
# L'encodeur d'images de LLaVA est conserv√© intact.
# 
# Architecture: CLIP ViT (LLaVA) + LLM fusionn√© (Vicuna + Llama 3.2)

# Mod√®les parents (LLM uniquement)
models:
  - model: liuhaotian/llava-v1.5-7b
    # On extrait uniquement le LLM (Vicuna 7B)
    # Expertise: Visual understanding, image description
    # Taille LLM: ~3.4 Go (sans l'encodeur)
    layers: llm  # Extraire uniquement les couches LLM
    
  - model: meta-llama/Llama-3.2-3B-Instruct
    # Expertise: Logical reasoning, step-by-step analysis
    # Taille: ~1.9 Go (q4)

# M√©thode de fusion
merge_method: slerp

# Param√®tres de fusion
parameters:
  # t=0.4 => 60% LLaVA + 40% Llama 3.2
  # Justification: On privil√©gie l'expertise vision de LLaVA
  # tout en ajoutant les capacit√©s de raisonnement de Llama 3.2
  t: 0.4

# Pr√©cision
dtype: bfloat16

# M√©tadonn√©es
metadata:
  name: "ORION-Vision-Logic-v1"
  description: "Agent hybride - Analyse visuelle avec raisonnement logique structur√©"
  created_by: "ORION Model Foundry"
  created_at: "2025-10-24"
  version: "1.0.0"
  
  # Architecture
  architecture:
    vision_encoder:
      source: "liuhaotian/llava-v1.5-7b"
      component: "CLIP ViT-L/14"
      size_mb: 600
      frozen: true  # Non fusionn√©, utilis√© tel quel
    llm:
      fusion: "Vicuna 7B (LLaVA) + Llama 3.2 3B"
      method: "slerp"
      ratio: "60/40"
      size_mb: 2800
  
  # Capabilities combin√©es
  capabilities:
    - image-understanding
    - visual-qa
    - image-description
    - object-detection
    - scene-analysis
    - logical-reasoning
    - step-by-step-visual-analysis
    - visual-debugging
  
  # Cas d'usage
  use_cases:
    - "Analyse d'images avec explication logique"
    - "D√©tection et classification d'objets avec raisonnement"
    - "D√©bogage visuel (UI, diagrammes, screenshots)"
    - "Extraction de texte (OCR) avec contexte"
    - "Analyse de graphiques et donn√©es visuelles"
    - "Description d√©taill√©e de sc√®nes complexes"
  
  # Tests de validation
  validation_tests:
    vision:
      - "D√©crire une image complexe en d√©tail"
      - "Identifier tous les objets dans une sc√®ne"
      - "Lire et extraire du texte d'une image"
    logical:
      - "Expliquer pourquoi une sc√®ne est compos√©e ainsi"
      - "Analyser √©tape par √©tape un diagramme"
      - "D√©duire le contexte d'une image"
    hybrid:
      - "Analyser un bug UI avec raisonnement logique"
      - "D√©crire une architecture technique depuis un diagramme"
      - "Expliquer un graphique de donn√©es complexe"
  
  # Configuration recommand√©e
  recommended_config:
    temperature: 0.5  # √âquilibr√©
    max_tokens: 4096
    top_p: 0.9
    
  # Optimisation web
  web_optimization:
    quantization: "q4"  # Vision sensible, q4 minimum
    sharding: true
    # Strat√©gie de sharding sp√©ciale:
    # - Encodeur vision: 1 shard complet (600 Mo)
    # - LLM: sharding progressif (2-4 shards initiaux)
    vision_encoder_sharding: false
    llm_sharding: true
    llm_shard_size_mb: 200
    estimated_size_mb: 3400
    
  # Notes importantes
  notes:
    - "‚ö†Ô∏è Architecture complexe: Encodeur vision + LLM fusionn√©"
    - "‚ö†Ô∏è L'encodeur vision DOIT √™tre charg√© compl√®tement"
    - "‚úÖ Le LLM peut utiliser le sharding progressif"
    - "üéØ TTFT optimis√©: Charger encodeur + premiers shards LLM (~1.2 Go)"
    - "üìä Chargement complet en arri√®re-plan (~3.4 Go total)"
  
  # Strat√©gie de chargement optimale
  loading_strategy:
    phase_1_initial:
      - component: "vision_encoder"
        size_mb: 600
        priority: "critical"
      - component: "llm_shard_1_2"
        size_mb: 400
        priority: "critical"
    phase_2_background:
      - component: "llm_remaining_shards"
        size_mb: 2400
        priority: "low"
    estimated_ttft: "8-12s"  # Time To First Token
    estimated_full_load: "30-45s"  # Chargement complet
