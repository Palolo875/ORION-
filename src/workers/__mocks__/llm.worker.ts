// src/workers/__mocks__/llm.worker.ts

/**
 * Mock du LLM Worker pour les tests
 * 
 * Ce mock simule le comportement du LLM Worker sans t√©l√©charger de mod√®les.
 * Il g√©n√®re des r√©ponses intelligentes bas√©es sur le system prompt et la requ√™te.
 * 
 * Usage:
 * - Par d√©faut en mode test (npm test)
 * - R√©ponses en 100ms au lieu de 5s
 * - D√©terministe et sans d√©pendance r√©seau
 */

import type { WorkerMessage, QueryPayload } from '../../types';

/**
 * Mock du Worker LLM
 * Simule les messages et r√©ponses d'un vrai worker
 */
export class MockLLMWorker {
  private listeners = new Map<string, (event: MessageEvent) => void>();
  private currentModel = "Phi-3-mini-4k-instruct-q4f16_1-MLC";
  
  postMessage(message: WorkerMessage<QueryPayload & { 
    context?: string[]; 
    modelId?: string; 
    systemPrompt?: string;
    temperature?: number;
    maxTokens?: number;
    agentType?: string;
  }>) {
    const { type, payload, meta } = message;
    
    // Simuler un d√©lai asynchrone (100ms au lieu de 5s)
    setTimeout(() => {
      const mockResponse = this.generateMockResponse(type, payload, meta);
      
      // Appeler le listener onmessage
      const listener = this.listeners.get('message');
      if (listener) {
        listener({ data: mockResponse });
      }
    }, 100);
  }
  
  addEventListener(event: string, callback: (event: MessageEvent) => void) {
    this.listeners.set(event, callback);
  }
  
  removeEventListener(event: string) {
    this.listeners.delete(event);
  }
  
  terminate() {
    this.listeners.clear();
  }
  
  /**
   * G√©n√®re une r√©ponse mock intelligente bas√©e sur le contexte
   */
  private generateMockResponse(
    type: string, 
    payload: Record<string, unknown>, 
    meta?: WorkerMessage['meta']
  ): WorkerMessage {
    if (type === 'set_model') {
      this.currentModel = payload.modelId || this.currentModel;
      return {
        type: 'model_set',
        payload: { modelId: this.currentModel },
        meta
      };
    }
    
    if (type === 'init') {
      return {
        type: 'init_complete',
        payload: {},
        meta
      };
    }
    
    if (type === 'generate_response') {
      // Simuler la progression du chargement (uniquement la premi√®re fois)
      const listener = this.listeners.get('message');
      if (listener) {
        // Envoyer quelques √©v√©nements de progression
        setTimeout(() => {
          listener({
            data: {
              type: 'llm_load_progress',
              payload: {
                progress: 0.3,
                text: '[Mock] Chargement du mod√®le...',
                loaded: 300,
                total: 1000,
                modelId: this.currentModel,
              },
              meta
            }
          });
        }, 10);
        
        setTimeout(() => {
          listener({
            data: {
              type: 'llm_load_progress',
              payload: {
                progress: 0.7,
                text: '[Mock] Initialisation...',
                loaded: 700,
                total: 1000,
                modelId: this.currentModel,
              },
              meta
            }
          });
        }, 50);
      }
      
      // G√©n√©rer la r√©ponse bas√©e sur le contexte
      const response = this.generateIntelligentResponse(payload);
      
      return {
        type: 'llm_response_complete',
        payload: {
          response,
          agentType: payload.agentType
        },
        meta
      };
    }
    
    // Type de message non g√©r√©
    return {
      type: 'llm_error',
      payload: {
        error: `[Mock] Type de message non g√©r√©: ${type}`,
        details: { type, payload }
      },
      meta
    };
  }
  
  /**
   * G√©n√®re une r√©ponse intelligente bas√©e sur le system prompt et la requ√™te
   */
  private generateIntelligentResponse(payload: {
    query: string;
    systemPrompt?: string;
    agentType?: string;
    context?: string[];
  }): string {
    const { query, systemPrompt = '', agentType, context } = payload;
    const lowerQuery = query.toLowerCase();
    const lowerPrompt = systemPrompt.toLowerCase();
    
    // R√©ponses sp√©cifiques par type d'agent (d√©bat multi-agents)
    if (agentType === 'logical') {
      return this.generateLogicalResponse(query, context);
    }
    
    if (agentType === 'creative') {
      return this.generateCreativeResponse(query, context);
    }
    
    if (agentType === 'critical') {
      return this.generateCriticalResponse(query, context);
    }
    
    if (agentType === 'synthesizer') {
      return this.generateSynthesizerResponse(query, context);
    }
    
    // R√©ponses bas√©es sur le system prompt
    if (lowerPrompt.includes('logique') || lowerPrompt.includes('logical')) {
      return this.generateLogicalResponse(query, context);
    }
    
    if (lowerPrompt.includes('cr√©atif') || lowerPrompt.includes('creative')) {
      return this.generateCreativeResponse(query, context);
    }
    
    if (lowerPrompt.includes('critique') || lowerPrompt.includes('critical')) {
      return this.generateCriticalResponse(query, context);
    }
    
    // R√©ponses bas√©es sur le type de requ√™te
    if (lowerQuery.includes('calcul') || lowerQuery.includes('math')) {
      return `[Mock] Calcul: Pour "${query}", le r√©sultat serait 42. (R√©ponse mock√©e)`;
    }
    
    if (lowerQuery.includes('code') || lowerQuery.includes('program')) {
      return `[Mock] Code:\n\`\`\`javascript\n// Exemple de code pour: ${query}\nfunction solution() {\n  return "mock";\n}\n\`\`\``;
    }
    
    if (lowerQuery.includes('explain') || lowerQuery.includes('expliquer')) {
      return `[Mock] Explication: ${query}\n\n1. Premier point d'explication\n2. Deuxi√®me point avec d√©tails\n3. Conclusion de l'explication\n\n${context && context.length > 0 ? `Contexte utilis√©: ${context.length} √©l√©ments` : ''}`;
    }
    
    // R√©ponse par d√©faut
    const contextInfo = context && context.length > 0 
      ? `\n\n(Contexte: ${context.length} √©l√©ments de m√©moire utilis√©s)`
      : '';
    
    return `[Mock LLM Response] R√©ponse √† la requ√™te: "${query.substring(0, 100)}..."\n\nCeci est une r√©ponse mock√©e g√©n√©r√©e pour les tests. En production, le vrai mod√®le LLM fournirait une r√©ponse d√©taill√©e et pertinente.${contextInfo}`;
  }
  
  /**
   * G√©n√®re une r√©ponse logique structur√©e
   */
  private generateLogicalResponse(query: string, context?: string[]): string {
    const contextInfo = context && context.length > 0 ? `\n\nContexte: ${context.length} √©l√©ments` : '';
    return `[Mock - Agent Logique] Analyse structur√©e de: "${query.substring(0, 50)}..."

**1. Pr√©misses**
- √âl√©ment A: Donn√©e factuelle identifi√©e
- √âl√©ment B: Relation causale observ√©e

**2. Raisonnement**
- Si A alors B (relation logique)
- B implique C (cons√©quence)

**3. Conclusion**
- R√©ponse d√©ductive bas√©e sur les pr√©misses
- Niveau de certitude: √âlev√©${contextInfo}`;
  }
  
  /**
   * G√©n√®re une r√©ponse cr√©ative et imaginative
   */
  private generateCreativeResponse(query: string, context?: string[]): string {
    const contextInfo = context && context.length > 0 ? `\n\nüí° Inspir√© par ${context.length} √©l√©ments de contexte` : '';
    return `[Mock - Agent Cr√©atif] Exploration cr√©ative de: "${query.substring(0, 50)}..."

üé® **M√©taphore**
Imaginons que cette question soit comme un oc√©an de possibilit√©s, o√π chaque vague repr√©sente une perspective unique...

üåü **Perspectives Innovantes**
1. Approche non conventionnelle: Et si nous envisagions le contraire?
2. Connexions inattendues: Lien avec un domaine apparemment sans rapport
3. Vision futuriste: Comment cela √©voluera-t-il dans 10 ans?

‚ú® **Synth√®se Cr√©ative**
La r√©ponse se trouve peut-√™tre dans la combinaison audacieuse de ces id√©es divergentes.${contextInfo}`;
  }
  
  /**
   * G√©n√®re une analyse critique
   */
  private generateCriticalResponse(query: string, context?: string[]): string {
    const contextInfo = context && context.length > 0 ? `\n\nüìä Bas√© sur ${context.length} sources` : '';
    return `[Mock - Agent Critique] √âvaluation critique de: "${query.substring(0, 50)}..."

‚ö†Ô∏è **Limites Identifi√©es**
- Biais potentiel #1: Hypoth√®se non v√©rifi√©e
- Lacune #2: Manque de donn√©es empiriques
- Risque #3: G√©n√©ralisation excessive

üîç **Points √† Questionner**
1. Cette affirmation est-elle support√©e par des preuves?
2. Existe-t-il des contre-exemples?
3. Quelles sont les alternatives non explor√©es?

üìã **Recommandations**
- Approfondir l'analyse avec des donn√©es suppl√©mentaires
- Consid√©rer des perspectives alternatives
- Valider les hypoth√®ses de base${contextInfo}`;
  }
  
  /**
   * G√©n√®re une synth√®se des diff√©rents agents
   */
  private generateSynthesizerResponse(query: string, context?: string[]): string {
    const contextInfo = context && context.length > 0 ? `\n\nüîó Int√©grant ${context.length} √©l√©ments` : '';
    return `[Mock - Agent Synth√©tiseur] Synth√®se finale pour: "${query.substring(0, 50)}..."

üéØ **Convergence des Perspectives**

**De l'Analyse Logique:**
- Structure argumentative solide
- Raisonnement d√©ductif valide

**De la Vision Cr√©ative:**
- Approches innovantes identifi√©es
- Connexions non conventionnelles

**De l'√âvaluation Critique:**
- Limites reconnues et adress√©es
- Points de vigilance not√©s

üåü **R√©ponse Synth√©tique**
En combinant rigueur logique, cr√©ativit√© et esprit critique, la meilleure r√©ponse serait une approche √©quilibr√©e qui:
1. S'appuie sur des faits v√©rifiables
2. Explore des solutions innovantes
3. Reste consciente de ses limites

Cette synth√®se offre une r√©ponse nuanc√©e et compl√®te.${contextInfo}`;
  }
}

// Export pour compatibilit√© avec le syst√®me de modules
export default MockLLMWorker;
